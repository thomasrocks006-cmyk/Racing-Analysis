# üéØ MASTER CONTEXT - Racing Analysis System

**Last Updated:** November 13, 2025
**Purpose:** Single source of truth for AI agents to understand the complete system architecture and implementation status
**Critical:** READ THIS FILE FIRST before making any architectural judgments or analysis

---

## üö® CRITICAL RULES FOR AI AGENTS

### **Rule #1: NEVER Simplify the Architecture**

The master plan is **correct as designed**. Do not suggest simplifications unless explicitly asked. The dual-pipeline + fusion model architecture is the competitive advantage.

### **Rule #2: NEVER Make Up Implementation Status**

- If you haven't read the actual code files, say "I need to check the implementation"
- Do not assume features exist based on documentation
- Always verify with `grep_search`, `read_file`, or `semantic_search` before claiming something is implemented

### **Rule #3: NEVER Hallucinate About What's Built**

The system has extensive documentation but **minimal working code**. Default assumption:

- ‚úÖ Documentation exists
- ‚ùå Implementation does NOT exist (until verified)

### **Rule #4: Build What Was Designed**

Follow MASTER_PLAN.md, FUSION_MODEL_ARCHITECTURE.md, and the 21-category taxonomy exactly as specified. These are correct and should not be changed without explicit user request.

---

## üìã PROJECT OVERVIEW

### **Project Name:** Racing Analysis System

### **Goal:** High-accuracy horse racing prediction using qualitative + quantitative dual-pipeline fusion

### **Core Architecture (DO NOT CHANGE):**

```
21-Category Taxonomy
    ‚Üì
Dual Pipeline System:
    ‚Üì
1. Qualitative Pipeline (Categories 1-17)
   - 6 stages with GPT-5/Gemini/Claude
   - Cost: $0.62/race
   - Time: 5-7 minutes
   - Output: Likelihood Ratios (LRs)
    ‚Üì
2. Quantitative Pipeline (Categories 18-21)
   - ML models (LightGBM/XGBoost/CatBoost)
   - Cost: <$0.01/race
   - Time: 10-30 seconds
   - Output: Base probabilities
    ‚Üì
3. Fusion Model (15 Concurrent Agents)
   - E2B sandboxes for parallel execution
   - OpenHands orchestration
   - Bayesian LR fusion
   - Consensus synthesis
   - Output: Final calibrated probabilities
```

### **Expected Performance (AS DESIGNED):**

- Brier score: <0.16
- ROI: >7.2%
- Calibration error: <2%
- Runtime: 30-60s (parallel execution)

---

## üìÅ CRITICAL DOCUMENTS (Read These Before Analysis)

### **Architecture & Planning:**

1. **MASTER_PLAN.md** (1039 lines)
   - Complete system architecture
   - Dual pipeline specifications
   - Implementation phases
   - **STATUS:** ‚úÖ Complete and correct

2. **FUSION_MODEL_ARCHITECTURE.md** (1530 lines)
   - 15-agent concurrent fusion design
   - E2B + OpenHands integration
   - Bayesian LR algorithms
   - **STATUS:** ‚úÖ Complete design, ‚ùå NOT IMPLEMENTED

3. **DATA_SOURCE_MAPPING_AND_SCRAPING_ARCHITECTURE.md**
   - All 21 categories ‚Üí data sources
   - 40+ scraper specifications
   - Implementation roadmap
   - **STATUS:** ‚úÖ Complete mapping created Nov 12, 2025

4. **COMPREHENSIVE_TAXONOMY_MASTER/** (26 parts, 16,926 lines)
   - Categories 1-21 detailed specifications
   - Integration matrices A/B/C
   - Implementation roadmaps
   - **STATUS:** ‚úÖ Complete specifications

### **Reality Check Documents:**

5. **IMPLEMENTATION_REALITY_CHECK.md**
   - Honest assessment: ~10% working code
   - What exists vs what's documented
   - **READ THIS to avoid false claims**

---

## üéØ WHAT ACTUALLY EXISTS (Implementation Status)

### ‚úÖ **COMPLETE:**

1. **Documentation (100%)**
   - Master plan ‚úÖ
   - Fusion model architecture ‚úÖ
   - 21-category taxonomy ‚úÖ
   - Data source mapping ‚úÖ

2. **Database Schema (90%)**
   - DuckDB with 13 tables ‚úÖ
   - Proper schema design ‚úÖ
   - Only ~10 placeholder races ‚ö†Ô∏è
   - Location: `src/data/init_db.py`, `src/data/schema.sql`

3. **Deployment Infrastructure (100%)**
   - Docker + docker-compose ‚úÖ
   - FastAPI server ‚úÖ
   - Prometheus + Grafana setup ‚úÖ
   - Location: `src/deployment/`, `docker-compose.yml`

### ‚ö†Ô∏è **PARTIAL (Exists but Incomplete):**

4. **Quantitative ML Pipeline (40%)**
   - Feature engineering code exists ‚ö†Ô∏è
   - ML models code exists ‚ö†Ô∏è
   - Calibration code exists ‚ö†Ô∏è
   - **BUT:** All trained on placeholder data
   - **Location:** `src/features/`, `src/models/`, `src/calibration/`
   - **Issue:** Cannot validate without real data

5. **Scrapers (5%)**
   - `src/data/scrapers/racing_com.py` - ‚ùå Returns fake data
   - `src/data/scrapers/stewards.py` - ‚ùå Returns fake data
   - `src/data/scrapers/market_odds.py` - ‚ùå Returns fake data
   - **Reality:** ZERO live web scraping implemented

6. **Orchestration (15%)**
   - Basic agent API wrappers exist ‚ö†Ô∏è
   - Location: `src/orchestration/agents/`
   - **BUT:** Not connected to fusion model
   - No E2B integration ‚ùå
   - No OpenHands integration ‚ùå

### ‚ùå **NOT IMPLEMENTED (0%):**

7. **Qualitative Pipeline (0%)**
   - No Stage 1: Source Planning ‚ùå
   - No Stage 2: Parallel Scraping ‚ùå
   - No Stage 3: Content Extraction ‚ùå
   - No Stage 4: Deep Reasoning (GPT-5) ‚ùå
   - No Stage 5: Synthesis (Claude) ‚ùå
   - No Stage 6: Quality Verification ‚ùå
   - **Directory doesn't exist:** `src/qualitative/` NOT FOUND

8. **Fusion Model (0%)**
   - `src/fusion/__init__.py` contains only: `"""Qualitative research fusion"""`
   - No Bayesian LR logic ‚ùå
   - No E2B integration ‚ùå
   - No OpenHands integration ‚ùå
   - No 15-agent system ‚ùå
   - No consensus synthesis ‚ùå

9. **Live Data Collection (0%)**
   - No Betfair API integration ‚ùå
   - No live racing.com scraping ‚ùå
   - No 15-40 sources per race ‚ùå
   - Database has ~10 placeholder races only

---

## üèóÔ∏è IMPLEMENTATION PRIORITIES (What to Build Next)

### **Phase 1: Data Foundation (Weeks 1-4)**

**Critical Path - System is non-functional without this**

1. **Week 1-2: Core Scrapers**
   - [ ] Rewrite `racing_com.py` with real BeautifulSoup scraping
   - [ ] Integrate Betfair API (Categories 8-9)
   - [ ] Build weather API integration (Category 3)
   - [ ] Populate 100+ historical races

2. **Week 3-4: Extended Scrapers**
   - [ ] Stewards reports scraper (PDF parsing)
   - [ ] Barrier trials scraper
   - [ ] Gear changes scraper
   - [ ] Expert commentary scraper
   - [ ] Target: 500+ historical races

### **Phase 2: Qualitative Pipeline (Weeks 5-8)**

**Competitive Advantage - Build as Designed**

3. **Week 5-6: Stages 1-3**
   - [ ] Stage 1: Source Planning (Gemini 2.5 Flash)
   - [ ] Stage 2: Parallel Scraping (15-40 sources)
   - [ ] Stage 3: Content Extraction (Gemini)

4. **Week 7-8: Stages 4-6**
   - [ ] Stage 4: Deep Reasoning (GPT-5 Extended Thinking)
   - [ ] Stage 5: Synthesis (Claude Sonnet 4.5)
   - [ ] Stage 6: Quality Verification (GPT-4o)

### **Phase 3: Fusion Model (Weeks 9-12)**

**Integration Layer - Build as Designed**

5. **Week 9-10: E2B + Bayesian Logic**
   - [ ] E2B sandbox integration
   - [ ] Bayesian LR update algorithm
   - [ ] Single-agent fusion (test)
   - [ ] Expand to 15 concurrent agents

6. **Week 11-12: OpenHands + Consensus**
   - [ ] OpenHands orchestration
   - [ ] Consensus synthesis
   - [ ] Outlier detection
   - [ ] Full system integration test

---

## üí° DESIGN PRINCIPLES (Never Violate These)

### **1. No Data Leakage**

- Strict event-time ordering
- Train/test splits respect time boundaries
- No look-ahead bias in features

### **2. Dual Pipeline Architecture**

- Qualitative (Categories 1-17) ‚Üí LRs
- Quantitative (Categories 18-21) ‚Üí Probabilities
- Fusion ‚Üí Combined predictions
- **Do not merge or simplify this structure**

### **3. Multi-Agent Fusion**

- 15 specialized agents with different strategies
- E2B parallel execution
- Consensus synthesis
- **Do not reduce to single agent unless explicitly requested**

### **4. 21-Category Taxonomy**

- Foundation of all feature engineering
- Each category has specific data sources
- Integration matrices link categories
- **Do not skip categories or merge them**

### **5. Uncertainty Quantification**

- All predictions include confidence intervals
- Conformal prediction sets
- Calibration monitoring
- **Never output point predictions without uncertainty**

---

## üîß WORKING STYLE & CONSTRAINTS

### **Code Quality:**

- Type hints required (Python 3.11+)
- Comprehensive error handling
- Logging for all major operations
- Unit tests for critical functions

### **Data Sources:**

- Non-commercial personal use only
- Respect rate limits (1-2 seconds between requests)
- Cache aggressively
- Handle failures gracefully

### **AI Model Usage:**

- GPT-5: Deep reasoning, contradiction resolution
- Claude Sonnet 4.5: Long-form synthesis, reports
- Gemini 2.5 Flash: Fast extraction, source planning
- GPT-4o: Quality verification, fact-checking

### **Performance Targets:**

- Qualitative pipeline: 5-7 minutes
- Quantitative pipeline: 10-30 seconds
- Fusion model: 30-60 seconds (parallel)
- Total end-to-end: 7-8 minutes max

---

## üìä CURRENT METRICS (What We Can Actually Measure)

### **Documentation:**

- Lines of specifications: 16,926 ‚úÖ
- Architecture documents: 85+ files ‚úÖ
- Completeness: 100% ‚úÖ

### **Implementation:**

- Python files: 75 files
- Total lines of code: ~11,000
- **Working scrapers: 0** ‚ùå
- **Historical races: ~10** ‚ùå
- **Qualitative pipeline: 0%** ‚ùå
- **Fusion model: 0%** ‚ùå

### **Validation Status:**

- Cannot validate backtests (no data) ‚ùå
- Cannot validate ROI (no data) ‚ùå
- Cannot validate Brier score (no data) ‚ùå
- **System is non-functional for production** ‚ùå

---

## üö® COMMON MISTAKES TO AVOID

### **Mistake #1: "We've built 60% of the system"**

‚ùå **FALSE** - We have ~10% working code
‚úÖ **TRUE** - We have 100% design documentation

### **Mistake #2: "Simplify the dual pipeline"**

‚ùå **NEVER** - The dual pipeline is the competitive advantage
‚úÖ **BUILD IT** - As designed in MASTER_PLAN.md

### **Mistake #3: "The quantitative pipeline is production-ready"**

‚ùå **FALSE** - It's trained on placeholder data only
‚úÖ **TRUE** - The code structure exists but needs real data

### **Mistake #4: "Maybe skip the qualitative pipeline"**

‚ùå **NEVER** - That's 30-40% of predictive signal
‚úÖ **BUILD IT** - All 6 stages as designed

### **Mistake #5: "15 agents is too complex, use 3"**

‚ùå **NO** - 15 agents reduces variance and improves consensus
‚úÖ **BUILD IT** - As designed in FUSION_MODEL_ARCHITECTURE.md

### **Mistake #6: "Scrapers are working"**

‚ùå **FALSE** - All scrapers return placeholder data
‚úÖ **TRUE** - We need to build 40+ live scrapers

---

## üìö KEY FILE LOCATIONS

### **Documentation:**

- Master plan: `MASTER_PLAN.md`
- Fusion architecture: `docs/FUSION_MODEL_ARCHITECTURE.md`
- Taxonomy: `docs/COMPREHENSIVE_TAXONOMY_MASTER/PART_*.md`
- Data sources: `DATA_SOURCE_MAPPING_AND_SCRAPING_ARCHITECTURE.md`

### **Implementation:**

- Database: `src/data/init_db.py`, `src/data/schema.sql`
- Scrapers: `src/data/scrapers/*.py` (all placeholder)
- Features: `src/features/*.py`
- Models: `src/models/*.py`
- Fusion: `src/fusion/__init__.py` (empty)
- Qualitative: NOT CREATED YET

### **Configuration:**

- Environment: `.env.example`
- Docker: `docker-compose.yml`
- Python: `pyproject.toml`

---

## üéØ VERIFICATION CHECKLIST (Before Making Claims)

Before saying something is "implemented" or "complete", verify:

1. [ ] Read the actual source file with `read_file`
2. [ ] Check for placeholder/fake data returns
3. [ ] Verify imports and dependencies exist
4. [ ] Check if directory structure exists
5. [ ] Search for actual implementation logic (not just comments)
6. [ ] Verify with `grep_search` for key functions/classes
7. [ ] Check git history if needed
8. [ ] Cross-reference with IMPLEMENTATION_REALITY_CHECK.md

**If you can't verify ‚Üí say "I need to check" ‚Üí do NOT assume it exists**

---

## üîÑ NEXT ACTIONS (Current Priority)

### **Immediate (This Week):**

1. Build racing.com live scraper (replace placeholder)
2. Integrate Betfair API
3. Populate 100 historical races

### **Short Term (Next 2 Weeks):**

4. Build remaining core scrapers (stewards, trials, gear)
5. Populate 500+ historical races
6. Begin qualitative pipeline Stage 1

### **Medium Term (Next 4-6 Weeks):**

7. Complete qualitative pipeline (all 6 stages)
8. Build fusion model (E2B + 15 agents)
9. Full system integration

### **Long Term (Next 8-12 Weeks):**

10. Production deployment
11. Live race validation
12. Performance optimization

---

## üß† CONTEXT FOR AGENTS

**When you're asked to analyze the system:**

1. Read MASTER_CONTEXT.md (this file) FIRST
2. Read IMPLEMENTATION_REALITY_CHECK.md
3. Read DATA_SOURCE_MAPPING_AND_SCRAPING_ARCHITECTURE.md
4. Then analyze actual code with verification

**When you're asked to build something:**

1. Check MASTER_PLAN.md for the designed architecture
2. Check FUSION_MODEL_ARCHITECTURE.md for fusion specs
3. Check COMPREHENSIVE_TAXONOMY_MASTER for category specs
4. Build exactly as designed (don't simplify)

**When you're unsure:**

1. Say "I need to verify this"
2. Use grep_search or read_file to check
3. Don't hallucinate or guess
4. Ask for clarification

---

## ‚úÖ CONFIDENCE INDICATORS

When making statements, use confidence indicators:

- **‚úÖ VERIFIED:** I have read the source code
- **üìã DOCUMENTED:** Exists in documentation but not verified in code
- **‚ö†Ô∏è UNCERTAIN:** Need to check actual implementation
- **‚ùå NOT IMPLEMENTED:** Confirmed absence of code
- **üîç NEED TO CHECK:** Should verify before claiming

---

**Last Updated:** November 13, 2025
**Maintained By:** Project team
**Version:** 1.0
**Next Review:** When significant architecture changes occur

---

# üéØ REMEMBER

## The system has EXCELLENT DESIGN but MINIMAL IMPLEMENTATION

**Do not confuse documentation completeness with code completeness**
